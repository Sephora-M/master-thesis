% !TEX root = ../thesis.tex

\chapter{Conclusion and Future Work}\label{chap:conclusion}
\section{Conclusion}
In this thesis, we aim to comprehend a better understanding over video-wise action recognition.

We started by diagnosing the shortcomings in current approaches, and concluded that performance of current approaches is weakened by the overfitting to ambiguous information. 
One of the causes lies CNN's inefficiency in identifying and separating relevant semantic cues from complex context.

To this end, we proposed a framework that explicitly integrates multiple semantic cues into the conventional CNN pipeline. 
Especially, we explored different fusion methods for combining the semantic cues and quantitatively investigated various training strategies better overall performance in terms of classification accuracy.
Furthermore we systematically evaluated the impact of each semantic cues and their actual contribution to different types of action classes.

The proposed model is computational efficient and modular, hence exhibiting great modeling capacity and flexibility.
In terms of classification performance, it exceeds the conventional two-stream CNN pipeline and yields state-of-the-art performance on challenging dataset.
\section{Future Work}
In our thesis, we have concluded that the separation of object channel does not make evident contribution to action recognition and a possible reason could be the lack of expressiveness in the representation.
As a potential future work, one could explore more explicit representations to describe human object interaction and more challengingly investigate the feasibility to incorporate such representations \textit{efficiently} in existing frameworks.

In the scope of this thesis, we adopted simple average pooling to obtain the video-wise classification result of 25 sampled frames (or sequences in temporal stream).
This setting enabled fair comparisons with related works, but neglected the fact that the importance among video frames in a video sequence is unequally distributed.
This issue has been addressed using recurrent neural network \cite{donahue2015long} or ranking based method \cite{fernando2015modeling}.
It would be interesting to incorporate semantic regional pooling with temporal pooling.

Last but not least, in our proposed system, object detections are generated during pre-processing externally using a separate CNN. 
It should be noticed that the detection CNN share great similarity with our action classification CNN.
Hence from the perspective of computational efficiency, it is worth experimenting the possibility to combine the both of them to create a model that generates salient semantic regions \textit{and} with the aid of the generated regions predicts action classes.